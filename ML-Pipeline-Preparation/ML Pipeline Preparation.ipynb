{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fernandes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/fernandes/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fernandes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'stopwords'])\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import pickle\n",
    "\n",
    "# import relevant functions/modules from the sklearn\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, f1_score, recall_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../ETL-Pipeline-Preparation/InsertDatabaseName.db')\n",
    "df = pd.read_sql_table(\"pipelines\", con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>original</th>\n",
       "      <th>genre</th>\n",
       "      <th>related</th>\n",
       "      <th>request</th>\n",
       "      <th>offer</th>\n",
       "      <th>aid_related</th>\n",
       "      <th>medical_help</th>\n",
       "      <th>medical_products</th>\n",
       "      <th>...</th>\n",
       "      <th>aid_centers</th>\n",
       "      <th>other_infrastructure</th>\n",
       "      <th>weather_related</th>\n",
       "      <th>floods</th>\n",
       "      <th>storm</th>\n",
       "      <th>fire</th>\n",
       "      <th>earthquake</th>\n",
       "      <th>cold</th>\n",
       "      <th>other_weather</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Weather update - a cold front from Cuba that c...</td>\n",
       "      <td>Un front froid se retrouve sur Cuba ce matin. ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>Is the Hurricane over or is it not over</td>\n",
       "      <td>Cyclone nan fini osinon li pa fini</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>Looking for someone but no name</td>\n",
       "      <td>Patnm, di Maryani relem pou li banm nouvel li ...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>UN reports Leogane 80-90 destroyed. Only Hospi...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>says: west side of Haiti, rest of the country ...</td>\n",
       "      <td>facade ouest d Haiti et le reste du pays aujou...</td>\n",
       "      <td>direct</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  \\\n",
       "0   2  Weather update - a cold front from Cuba that c...   \n",
       "1   7            Is the Hurricane over or is it not over   \n",
       "2   8                    Looking for someone but no name   \n",
       "3   9  UN reports Leogane 80-90 destroyed. Only Hospi...   \n",
       "4  12  says: west side of Haiti, rest of the country ...   \n",
       "\n",
       "                                            original   genre  related  \\\n",
       "0  Un front froid se retrouve sur Cuba ce matin. ...  direct        1   \n",
       "1                 Cyclone nan fini osinon li pa fini  direct        1   \n",
       "2  Patnm, di Maryani relem pou li banm nouvel li ...  direct        1   \n",
       "3  UN reports Leogane 80-90 destroyed. Only Hospi...  direct        1   \n",
       "4  facade ouest d Haiti et le reste du pays aujou...  direct        1   \n",
       "\n",
       "   request  offer  aid_related  medical_help  medical_products  ...  \\\n",
       "0        0      0            0             0                 0  ...   \n",
       "1        0      0            1             0                 0  ...   \n",
       "2        0      0            0             0                 0  ...   \n",
       "3        1      0            1             0                 1  ...   \n",
       "4        0      0            0             0                 0  ...   \n",
       "\n",
       "   aid_centers  other_infrastructure  weather_related  floods  storm  fire  \\\n",
       "0            0                     0                0       0      0     0   \n",
       "1            0                     0                1       0      1     0   \n",
       "2            0                     0                0       0      0     0   \n",
       "3            0                     0                0       0      0     0   \n",
       "4            0                     0                0       0      0     0   \n",
       "\n",
       "   earthquake  cold  other_weather  direct_report  \n",
       "0           0     0              0              0  \n",
       "1           0     0              0              0  \n",
       "2           0     0              0              0  \n",
       "3           0     0              0              0  \n",
       "4           0     0              0              0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         int64\n",
       "message                   object\n",
       "original                  object\n",
       "genre                     object\n",
       "related                    int64\n",
       "request                    int64\n",
       "offer                      int64\n",
       "aid_related                int64\n",
       "medical_help               int64\n",
       "medical_products           int64\n",
       "search_and_rescue          int64\n",
       "security                   int64\n",
       "military                   int64\n",
       "child_alone                int64\n",
       "water                      int64\n",
       "food                       int64\n",
       "shelter                    int64\n",
       "clothing                   int64\n",
       "money                      int64\n",
       "missing_people             int64\n",
       "refugees                   int64\n",
       "death                      int64\n",
       "other_aid                  int64\n",
       "infrastructure_related     int64\n",
       "transport                  int64\n",
       "buildings                  int64\n",
       "electricity                int64\n",
       "tools                      int64\n",
       "hospitals                  int64\n",
       "shops                      int64\n",
       "aid_centers                int64\n",
       "other_infrastructure       int64\n",
       "weather_related            int64\n",
       "floods                     int64\n",
       "storm                      int64\n",
       "fire                       int64\n",
       "earthquake                 int64\n",
       "cold                       int64\n",
       "other_weather              int64\n",
       "direct_report              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"message\"]\n",
    "y = df.iloc[:,4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        Weather update - a cold front from Cuba that c...\n",
      "1                  Is the Hurricane over or is it not over\n",
      "2                          Looking for someone but no name\n",
      "3        UN reports Leogane 80-90 destroyed. Only Hospi...\n",
      "4        says: west side of Haiti, rest of the country ...\n",
      "                               ...                        \n",
      "26211    The training demonstrated how to enhance micro...\n",
      "26212    A suitable candidate has been selected and OCH...\n",
      "26213    Proshika, operating in Cox's Bazar municipalit...\n",
      "26214    Some 2,000 women protesting against the conduc...\n",
      "26215    A radical shift in thinking came about as a re...\n",
      "Name: message, Length: 26216, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
      "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
      "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
      "       'missing_people', 'refugees', 'death', 'other_aid',\n",
      "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
      "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
      "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
      "       'other_weather', 'direct_report'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26216,), (26216, 36))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = y.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Normalize, tokenize and stem text string\n",
    "    \n",
    "    Args:\n",
    "    text: string. String containing message for processing\n",
    "       \n",
    "    Returns:\n",
    "    stemmed: list of strings. List containing normalized and stemmed word tokens\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline =  Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(warm_start=True))),\n",
    "    ], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline: xgb_pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "         ('ohe_onestep', CountVectorizer(tokenizer = tokenize)),\n",
    "         ('xgb_model', xgb.XGBRegressor())\n",
    "     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19662,)\n",
      "(6554,)\n",
      "(19662, 36)\n",
      "(6554, 36)\n"
     ]
    }
   ],
   "source": [
    "# Quick check to examine what we have got\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  10.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 7.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train classifier\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('ohe_onestep',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>)),\n",
       "                ('xgb_model',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "                              colsample_bylevel=1, colsample_bynode=1,\n",
       "                              colsample_bytree=1, early_stopping_rounds=None,\n",
       "                              enable_categorical=False, eval_metric=None,\n",
       "                              gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "                              importance_type=None, interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_bin=256,\n",
       "                              max_cat_to_onehot=4, max_delta_step=0,\n",
       "                              max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "                              missing=nan, monotone_constraints='()',\n",
       "                              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "                              predictor='auto', random_state=0, reg_alpha=0,\n",
       "                              reg_lambda=1, ...))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the XGBregressor pipeline\n",
    "pipeline_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Prediction\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the classification report for each label\n",
    "def model_report(y_test, y_pred):\n",
    "    i = 0\n",
    "    for col in y_test:\n",
    "        print('Feature {}: {}'.format(i+1, col))\n",
    "        print(classification_report(y_test[col], y_pred[:, i]))\n",
    "        i = i + 1\n",
    "    accuracy = (y_pred == y_test.values).mean()\n",
    "    print('The model accuracy is {:.3f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1: related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.29      0.42      1515\n",
      "           1       0.82      0.97      0.89      4993\n",
      "           2       0.37      0.43      0.40        46\n",
      "\n",
      "    accuracy                           0.81      6554\n",
      "   macro avg       0.65      0.56      0.57      6554\n",
      "weighted avg       0.80      0.81      0.77      6554\n",
      "\n",
      "Feature 2: request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      5433\n",
      "           1       0.91      0.45      0.60      1121\n",
      "\n",
      "    accuracy                           0.90      6554\n",
      "   macro avg       0.90      0.72      0.77      6554\n",
      "weighted avg       0.90      0.90      0.88      6554\n",
      "\n",
      "Feature 3: offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6526\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "Feature 4: aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.82      3833\n",
      "           1       0.79      0.62      0.70      2721\n",
      "\n",
      "    accuracy                           0.78      6554\n",
      "   macro avg       0.78      0.75      0.76      6554\n",
      "weighted avg       0.78      0.78      0.77      6554\n",
      "\n",
      "Feature 5: medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      6047\n",
      "           1       0.67      0.07      0.13       507\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.80      0.54      0.55      6554\n",
      "weighted avg       0.91      0.93      0.90      6554\n",
      "\n",
      "Feature 6: medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6225\n",
      "           1       0.69      0.07      0.12       329\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.82      0.53      0.55      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      "\n",
      "Feature 7: search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6364\n",
      "           1       0.89      0.04      0.08       190\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.93      0.52      0.53      6554\n",
      "weighted avg       0.97      0.97      0.96      6554\n",
      "\n",
      "Feature 8: security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6451\n",
      "           1       0.20      0.01      0.02       103\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.59      0.50      0.51      6554\n",
      "weighted avg       0.97      0.98      0.98      6554\n",
      "\n",
      "Feature 9: military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6334\n",
      "           1       0.71      0.02      0.04       220\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.84      0.51      0.51      6554\n",
      "weighted avg       0.96      0.97      0.95      6554\n",
      "\n",
      "Feature 10: child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6554\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       1.00      1.00      1.00      6554\n",
      "weighted avg       1.00      1.00      1.00      6554\n",
      "\n",
      "Feature 11: water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6137\n",
      "           1       0.96      0.23      0.37       417\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.95      0.61      0.67      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "Feature 12: food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      5843\n",
      "           1       0.83      0.41      0.55       711\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.88      0.70      0.75      6554\n",
      "weighted avg       0.92      0.93      0.92      6554\n",
      "\n",
      "Feature 13: shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      5973\n",
      "           1       0.87      0.27      0.42       581\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.90      0.63      0.69      6554\n",
      "weighted avg       0.93      0.93      0.92      6554\n",
      "\n",
      "Feature 14: clothing\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6462\n",
      "           1       0.83      0.11      0.19        92\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.91      0.55      0.59      6554\n",
      "weighted avg       0.99      0.99      0.98      6554\n",
      "\n",
      "Feature 15: money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6414\n",
      "           1       1.00      0.02      0.04       140\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.99      0.51      0.52      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "Feature 16: missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6472\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 17: refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6335\n",
      "           1       0.40      0.02      0.03       219\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.68      0.51      0.51      6554\n",
      "weighted avg       0.95      0.97      0.95      6554\n",
      "\n",
      "Feature 18: death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6254\n",
      "           1       0.81      0.13      0.22       300\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.88      0.56      0.60      6554\n",
      "weighted avg       0.95      0.96      0.94      6554\n",
      "\n",
      "Feature 19: other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5672\n",
      "           1       0.67      0.02      0.04       882\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.77      0.51      0.48      6554\n",
      "weighted avg       0.84      0.87      0.81      6554\n",
      "\n",
      "Feature 20: infrastructure_related\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6130\n",
      "           1       1.00      0.00      0.00       424\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.97      0.50      0.49      6554\n",
      "weighted avg       0.94      0.94      0.90      6554\n",
      "\n",
      "Feature 21: transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6256\n",
      "           1       0.85      0.10      0.17       298\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.91      0.55      0.58      6554\n",
      "weighted avg       0.95      0.96      0.94      6554\n",
      "\n",
      "Feature 22: buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6209\n",
      "           1       1.00      0.08      0.15       345\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.98      0.54      0.56      6554\n",
      "weighted avg       0.95      0.95      0.93      6554\n",
      "\n",
      "Feature 23: electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6427\n",
      "           1       1.00      0.03      0.06       127\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.99      0.52      0.53      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "Feature 24: tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6514\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "Feature 25: hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6486\n",
      "           1       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 26: shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6515\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "Feature 27: aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6477\n",
      "           1       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 28: other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6267\n",
      "           1       0.00      0.00      0.00       287\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.48      0.50      0.49      6554\n",
      "weighted avg       0.91      0.96      0.93      6554\n",
      "\n",
      "Feature 29: weather_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      4748\n",
      "           1       0.83      0.64      0.72      1806\n",
      "\n",
      "    accuracy                           0.86      6554\n",
      "   macro avg       0.85      0.79      0.82      6554\n",
      "weighted avg       0.86      0.86      0.86      6554\n",
      "\n",
      "Feature 30: floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6026\n",
      "           1       0.88      0.41      0.56       528\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.92      0.70      0.77      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "Feature 31: storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      5968\n",
      "           1       0.77      0.46      0.58       586\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.86      0.72      0.77      6554\n",
      "weighted avg       0.93      0.94      0.93      6554\n",
      "\n",
      "Feature 32: fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6478\n",
      "           1       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 33: earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      5952\n",
      "           1       0.91      0.75      0.82       602\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.94      0.87      0.90      6554\n",
      "weighted avg       0.97      0.97      0.97      6554\n",
      "\n",
      "Feature 34: cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6431\n",
      "           1       0.71      0.04      0.08       123\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.85      0.52      0.53      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "Feature 35: other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6199\n",
      "           1       0.44      0.01      0.02       355\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.70      0.51      0.50      6554\n",
      "weighted avg       0.92      0.95      0.92      6554\n",
      "\n",
      "Feature 36: direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      5273\n",
      "           1       0.89      0.35      0.50      1281\n",
      "\n",
      "    accuracy                           0.86      6554\n",
      "   macro avg       0.87      0.67      0.71      6554\n",
      "weighted avg       0.87      0.86      0.84      6554\n",
      "\n",
      "The model accuracy is 0.947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction: XGB Regressor \n",
    "y_pred = pipeline_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model performance for testing set\n",
      "--------------------------------------\n",
      "RMSE is 0.19888784345199914\n",
      "R2 score is 0.22420125506426614\n",
      "MAE score is 0.07598837058144\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"The model performance for testing set\")\n",
    "print(\"--------------------------------------\")\n",
    "print('RMSE is {}'.format(rmse))\n",
    "print('R2 score is {}'.format(r2))\n",
    "print('MAE score is {}'.format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)))],\n",
       " 'verbose': True,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': True,\n",
       " 'clf__estimator': RandomForestClassifier(warm_start=True),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show parameters for the pipeline\n",
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__estimator': (MultinomialNB(), \n",
    "                       RandomForestClassifier(warm_start=True))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)))],\n",
       "                                verbose=True),\n",
       "             n_jobs=1,\n",
       "             param_grid={'clf__estimator': (MultinomialNB(),\n",
       "                                            RandomForestClassifier(warm_start=True))},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = GridSearchCV(pipeline, parameters, cv=3, n_jobs=1, verbose=10)\n",
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "[CV 1/3; 1/2] START clf__estimator=MultinomialNB()..............................\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.4s\n",
      "[CV 1/3; 1/2] END clf__estimator=MultinomialNB();, score=0.165 total time=  15.8s\n",
      "[CV 2/3; 1/2] START clf__estimator=MultinomialNB()..............................\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "[CV 2/3; 1/2] END clf__estimator=MultinomialNB();, score=0.162 total time=   9.8s\n",
      "[CV 3/3; 1/2] START clf__estimator=MultinomialNB()..............................\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "[CV 3/3; 1/2] END clf__estimator=MultinomialNB();, score=0.153 total time=  11.0s\n",
      "[CV 1/3; 2/2] START clf__estimator=RandomForestClassifier(warm_start=True)......\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 4.7min\n",
      "[CV 1/3; 2/2] END clf__estimator=RandomForestClassifier(warm_start=True);, score=0.236 total time= 5.2min\n",
      "[CV 2/3; 2/2] START clf__estimator=RandomForestClassifier(warm_start=True)......\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   8.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 4.5min\n",
      "[CV 2/3; 2/2] END clf__estimator=RandomForestClassifier(warm_start=True);, score=0.245 total time= 5.1min\n",
      "[CV 3/3; 2/2] START clf__estimator=RandomForestClassifier(warm_start=True)......\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 5.4min\n",
      "[CV 3/3; 2/2] END clf__estimator=RandomForestClassifier(warm_start=True);, score=0.241 total time= 5.8min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   9.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 8.5min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)))],\n",
       "                                verbose=True),\n",
       "             n_jobs=1,\n",
       "             param_grid={'clf__estimator': (MultinomialNB(),\n",
       "                                            RandomForestClassifier(warm_start=True))},\n",
       "             verbose=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator': RandomForestClassifier(warm_start=True)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the first tuned model \n",
    "ypred_test = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1: related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.29      0.42      1515\n",
      "           1       0.82      0.97      0.89      4993\n",
      "           2       0.44      0.48      0.46        46\n",
      "\n",
      "    accuracy                           0.81      6554\n",
      "   macro avg       0.67      0.58      0.59      6554\n",
      "weighted avg       0.80      0.81      0.77      6554\n",
      "\n",
      "Feature 2: request\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      5433\n",
      "           1       0.90      0.46      0.61      1121\n",
      "\n",
      "    accuracy                           0.90      6554\n",
      "   macro avg       0.90      0.72      0.77      6554\n",
      "weighted avg       0.90      0.90      0.88      6554\n",
      "\n",
      "Feature 3: offer\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6526\n",
      "           1       0.00      0.00      0.00        28\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      1.00      0.99      6554\n",
      "\n",
      "Feature 4: aid_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      3833\n",
      "           1       0.79      0.63      0.70      2721\n",
      "\n",
      "    accuracy                           0.78      6554\n",
      "   macro avg       0.78      0.76      0.76      6554\n",
      "weighted avg       0.78      0.78      0.77      6554\n",
      "\n",
      "Feature 5: medical_help\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      6047\n",
      "           1       0.57      0.05      0.10       507\n",
      "\n",
      "    accuracy                           0.92      6554\n",
      "   macro avg       0.75      0.52      0.53      6554\n",
      "weighted avg       0.90      0.92      0.89      6554\n",
      "\n",
      "Feature 6: medical_products\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      6225\n",
      "           1       0.76      0.07      0.12       329\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.86      0.53      0.55      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      "\n",
      "Feature 7: search_and_rescue\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      6364\n",
      "           1       0.60      0.02      0.03       190\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.79      0.51      0.51      6554\n",
      "weighted avg       0.96      0.97      0.96      6554\n",
      "\n",
      "Feature 8: security\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6451\n",
      "           1       0.20      0.01      0.02       103\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.59      0.50      0.51      6554\n",
      "weighted avg       0.97      0.98      0.98      6554\n",
      "\n",
      "Feature 9: military\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6334\n",
      "           1       0.78      0.03      0.06       220\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.87      0.52      0.52      6554\n",
      "weighted avg       0.96      0.97      0.95      6554\n",
      "\n",
      "Feature 10: child_alone\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6554\n",
      "\n",
      "    accuracy                           1.00      6554\n",
      "   macro avg       1.00      1.00      1.00      6554\n",
      "weighted avg       1.00      1.00      1.00      6554\n",
      "\n",
      "Feature 11: water\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6137\n",
      "           1       0.92      0.24      0.37       417\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.93      0.62      0.67      6554\n",
      "weighted avg       0.95      0.95      0.94      6554\n",
      "\n",
      "Feature 12: food\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      5843\n",
      "           1       0.85      0.44      0.58       711\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.89      0.71      0.77      6554\n",
      "weighted avg       0.93      0.93      0.92      6554\n",
      "\n",
      "Feature 13: shelter\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      5973\n",
      "           1       0.87      0.22      0.36       581\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.90      0.61      0.66      6554\n",
      "weighted avg       0.92      0.93      0.91      6554\n",
      "\n",
      "Feature 14: clothing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6462\n",
      "           1       0.75      0.07      0.12        92\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.87      0.53      0.56      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 15: money\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6414\n",
      "           1       1.00      0.01      0.03       140\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.99      0.51      0.51      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "Feature 16: missing_people\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6472\n",
      "           1       0.00      0.00      0.00        82\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 17: refugees\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6335\n",
      "           1       0.46      0.03      0.05       219\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.71      0.51      0.52      6554\n",
      "weighted avg       0.95      0.97      0.95      6554\n",
      "\n",
      "Feature 18: death\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6254\n",
      "           1       0.80      0.12      0.21       300\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.88      0.56      0.59      6554\n",
      "weighted avg       0.95      0.96      0.94      6554\n",
      "\n",
      "Feature 19: other_aid\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93      5672\n",
      "           1       0.63      0.02      0.04       882\n",
      "\n",
      "    accuracy                           0.87      6554\n",
      "   macro avg       0.75      0.51      0.48      6554\n",
      "weighted avg       0.84      0.87      0.81      6554\n",
      "\n",
      "Feature 20: infrastructure_related\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      6130\n",
      "           1       0.00      0.00      0.00       424\n",
      "\n",
      "    accuracy                           0.94      6554\n",
      "   macro avg       0.47      0.50      0.48      6554\n",
      "weighted avg       0.87      0.94      0.90      6554\n",
      "\n",
      "Feature 21: transport\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6256\n",
      "           1       0.68      0.08      0.15       298\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.82      0.54      0.56      6554\n",
      "weighted avg       0.95      0.96      0.94      6554\n",
      "\n",
      "Feature 22: buildings\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6209\n",
      "           1       0.92      0.07      0.13       345\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.94      0.53      0.55      6554\n",
      "weighted avg       0.95      0.95      0.93      6554\n",
      "\n",
      "Feature 23: electricity\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6427\n",
      "           1       0.83      0.04      0.08       127\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.91      0.52      0.53      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "Feature 24: tools\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6514\n",
      "           1       0.00      0.00      0.00        40\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "Feature 25: hospitals\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6486\n",
      "           1       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 26: shops\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      6515\n",
      "           1       0.00      0.00      0.00        39\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.50      0.50      0.50      6554\n",
      "weighted avg       0.99      0.99      0.99      6554\n",
      "\n",
      "Feature 27: aid_centers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6477\n",
      "           1       0.00      0.00      0.00        77\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 28: other_infrastructure\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6267\n",
      "           1       0.00      0.00      0.00       287\n",
      "\n",
      "    accuracy                           0.96      6554\n",
      "   macro avg       0.48      0.50      0.49      6554\n",
      "weighted avg       0.91      0.96      0.93      6554\n",
      "\n",
      "Feature 29: weather_related\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91      4748\n",
      "           1       0.83      0.64      0.72      1806\n",
      "\n",
      "    accuracy                           0.86      6554\n",
      "   macro avg       0.85      0.79      0.82      6554\n",
      "weighted avg       0.86      0.86      0.86      6554\n",
      "\n",
      "Feature 30: floods\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6026\n",
      "           1       0.89      0.37      0.52       528\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.92      0.68      0.74      6554\n",
      "weighted avg       0.94      0.95      0.93      6554\n",
      "\n",
      "Feature 31: storm\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96      5968\n",
      "           1       0.74      0.40      0.52       586\n",
      "\n",
      "    accuracy                           0.93      6554\n",
      "   macro avg       0.84      0.70      0.74      6554\n",
      "weighted avg       0.93      0.93      0.93      6554\n",
      "\n",
      "Feature 32: fire\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      6478\n",
      "           1       0.00      0.00      0.00        76\n",
      "\n",
      "    accuracy                           0.99      6554\n",
      "   macro avg       0.49      0.50      0.50      6554\n",
      "weighted avg       0.98      0.99      0.98      6554\n",
      "\n",
      "Feature 33: earthquake\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      5952\n",
      "           1       0.89      0.75      0.81       602\n",
      "\n",
      "    accuracy                           0.97      6554\n",
      "   macro avg       0.93      0.87      0.90      6554\n",
      "weighted avg       0.97      0.97      0.97      6554\n",
      "\n",
      "Feature 34: cold\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6431\n",
      "           1       0.73      0.07      0.12       123\n",
      "\n",
      "    accuracy                           0.98      6554\n",
      "   macro avg       0.85      0.53      0.56      6554\n",
      "weighted avg       0.98      0.98      0.97      6554\n",
      "\n",
      "Feature 35: other_weather\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      6199\n",
      "           1       0.50      0.01      0.02       355\n",
      "\n",
      "    accuracy                           0.95      6554\n",
      "   macro avg       0.72      0.51      0.50      6554\n",
      "weighted avg       0.92      0.95      0.92      6554\n",
      "\n",
      "Feature 36: direct_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92      5273\n",
      "           1       0.88      0.36      0.51      1281\n",
      "\n",
      "    accuracy                           0.86      6554\n",
      "   macro avg       0.87      0.67      0.71      6554\n",
      "weighted avg       0.87      0.86      0.84      6554\n",
      "\n",
      "The model accuracy is 0.946\n"
     ]
    }
   ],
   "source": [
    "# Predicting using the first tuned model \n",
    "model_report(y_test, ypred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_pipeline =  Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier(warm_start=True))),\n",
    "    ], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('vect',\n",
       "   CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>)),\n",
       "  ('tfidf', TfidfTransformer()),\n",
       "  ('clf',\n",
       "   MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)))],\n",
       " 'verbose': True,\n",
       " 'vect': CountVectorizer(tokenizer=<function tokenize at 0x7f866ff5f320>),\n",
       " 'tfidf': TfidfTransformer(),\n",
       " 'clf': MultiOutputClassifier(estimator=RandomForestClassifier(warm_start=True)),\n",
       " 'vect__analyzer': 'word',\n",
       " 'vect__binary': False,\n",
       " 'vect__decode_error': 'strict',\n",
       " 'vect__dtype': numpy.int64,\n",
       " 'vect__encoding': 'utf-8',\n",
       " 'vect__input': 'content',\n",
       " 'vect__lowercase': True,\n",
       " 'vect__max_df': 1.0,\n",
       " 'vect__max_features': None,\n",
       " 'vect__min_df': 1,\n",
       " 'vect__ngram_range': (1, 1),\n",
       " 'vect__preprocessor': None,\n",
       " 'vect__stop_words': None,\n",
       " 'vect__strip_accents': None,\n",
       " 'vect__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'vect__tokenizer': <function __main__.tokenize(text)>,\n",
       " 'vect__vocabulary': None,\n",
       " 'tfidf__norm': 'l2',\n",
       " 'tfidf__smooth_idf': True,\n",
       " 'tfidf__sublinear_tf': False,\n",
       " 'tfidf__use_idf': True,\n",
       " 'clf__estimator__bootstrap': True,\n",
       " 'clf__estimator__ccp_alpha': 0.0,\n",
       " 'clf__estimator__class_weight': None,\n",
       " 'clf__estimator__criterion': 'gini',\n",
       " 'clf__estimator__max_depth': None,\n",
       " 'clf__estimator__max_features': 'auto',\n",
       " 'clf__estimator__max_leaf_nodes': None,\n",
       " 'clf__estimator__max_samples': None,\n",
       " 'clf__estimator__min_impurity_decrease': 0.0,\n",
       " 'clf__estimator__min_samples_leaf': 1,\n",
       " 'clf__estimator__min_samples_split': 2,\n",
       " 'clf__estimator__min_weight_fraction_leaf': 0.0,\n",
       " 'clf__estimator__n_estimators': 100,\n",
       " 'clf__estimator__n_jobs': None,\n",
       " 'clf__estimator__oob_score': False,\n",
       " 'clf__estimator__random_state': None,\n",
       " 'clf__estimator__verbose': 0,\n",
       " 'clf__estimator__warm_start': True,\n",
       " 'clf__estimator': RandomForestClassifier(warm_start=True),\n",
       " 'clf__n_jobs': None}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'clf__estimator__n_estimators': [50, 100, 200],\n",
    "        'clf__estimator__min_samples_split': [2, 3, 4],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(improved_pipeline, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.5s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 2.8min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 3.0min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  10.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 3.4min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  12.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 3.2min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   8.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.1s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 2.6min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   5.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 5.8min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  10.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 8.3min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   8.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 7.0min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 5.9min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   8.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 6.2min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   8.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 8.7min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   5.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=10.9min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   5.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=10.7min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   5.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=10.7min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.4s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=10.6min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   5.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 2.2min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 2.2min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 2.8min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 2.5min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   6.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 2.5min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   7.1s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total= 7.5min\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   9.2s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n"
     ]
    }
   ],
   "source": [
    "#Use improved pipeline\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ypred_train = pipeline_imp.predict(X_train)\n",
    "ypred_test_improved = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the first tuned model \n",
    "model_report(y_test, ypred_test_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pickle file for the model\n",
    "file_name = 'classifier-000.pkl'\n",
    "with open (file_name, 'wb') as f:\n",
    "    pickle.dump(cv, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
